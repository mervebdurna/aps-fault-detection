{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scania Truck Air Pressure Sensor Failure Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 90,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
<<<<<<< HEAD
=======
    "from imblearn.combine import SMOTETomek\n",
    "\n",
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 57,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_clf_performance_metrics(true, predicted):\n",
    "    '''\n",
    "    This function takes in true values and predicted values\n",
    "    Returns: Accuracy, F1-Score, Precision, Recall, Roc-auc Score\n",
    "    '''\n",
    "    acc = accuracy_score(true, predicted) \n",
    "    f1 = f1_score(true, predicted) \n",
    "    precision = precision_score(true, predicted) \n",
    "    recall = recall_score(true, predicted) \n",
    "    roc_auc = roc_auc_score(true, predicted) \n",
    "    return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 58,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cost of the model as per data description\n",
    "def calculate_total_cost(y_true, y_pred):\n",
    "    '''\n",
    "    This function takes y_ture, y_predicted, and returns Total cost due to misclassification\n",
    "\n",
    "    Cost-metric of miss-classification:\n",
    "\n",
    "     Predicted class |      True class       |\n",
    "                     |    pos    |    neg    |\n",
    "     -----------------------------------------\n",
    "      pos            |     -     |  Cost_1   |\n",
    "     -----------------------------------------\n",
    "      neg            |  Cost_2   |     -     |\n",
    "     -----------------------------------------\n",
    "\n",
    "     Cost_1 = 10 and cost_2 = 500\n",
    "     Total_cost = Cost_1*No_Instances + Cost_2*No_Instances.\n",
    "\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = 10*fp + 500*fn\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 59,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report \n",
    "def evaluate_models(X, y, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "    It splits the data into Train Test split\n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    # separate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    cost_list=[]\n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Training set performance\n",
    "        model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "        model_train_recall,model_train_rocauc_score=calculate_clf_performance_metrics(y_train ,y_train_pred)\n",
    "        train_cost = calculate_total_cost(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "        # Test set performance\n",
    "        model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "        model_test_recall,model_test_rocauc_score=calculate_clf_performance_metrics(y_test, y_test_pred)\n",
    "        test_cost = calculate_total_cost(y_test, y_test_pred)\n",
    "\n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        print(f'- COST: {train_cost}.')\n",
    "\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('Model performance for Test set')\n",
    "        print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "        print(f'- COST: {test_cost}.')\n",
    "        cost_list.append(test_cost)\n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "        \n",
    "    report=pd.DataFrame(list(zip(models_list, cost_list)), columns=['Model Name', 'Cost']).sort_values(by=[\"Cost\"])\n",
    "        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 60,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('aps_failure_training_set1.csv',na_values='na')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 61,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36188, 171)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 6,
=======
     "execution_count": 61,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rows and columns \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 62,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>153204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129862.0</td>\n",
       "      <td>26872.0</td>\n",
       "      <td>34044.0</td>\n",
       "      <td>22472.0</td>\n",
       "      <td>34362.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>453236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7908038.0</td>\n",
       "      <td>3026002.0</td>\n",
       "      <td>5025350.0</td>\n",
       "      <td>2025766.0</td>\n",
       "      <td>1160638.0</td>\n",
       "      <td>533834.0</td>\n",
       "      <td>493800.0</td>\n",
       "      <td>6914.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>72504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>178226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1432098.0</td>\n",
       "      <td>372252.0</td>\n",
       "      <td>527514.0</td>\n",
       "      <td>358274.0</td>\n",
       "      <td>332818.0</td>\n",
       "      <td>284178.0</td>\n",
       "      <td>3742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>762958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>776.0</td>\n",
       "      <td>281128.0</td>\n",
       "      <td>2186308.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>695994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1397742.0</td>\n",
       "      <td>495544.0</td>\n",
       "      <td>361646.0</td>\n",
       "      <td>28610.0</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  aa_000  ab_000  ac_000  ad_000  ae_000  af_000  ag_000    ag_001  \\\n",
       "0   pos  153204     0.0   182.0     NaN     0.0     0.0     0.0       0.0   \n",
       "1   pos  453236     NaN  2926.0     NaN     0.0     0.0     0.0       0.0   \n",
       "2   pos   72504     NaN  1594.0  1052.0     0.0     0.0     0.0     244.0   \n",
       "3   pos  762958     NaN     NaN     NaN     NaN     NaN   776.0  281128.0   \n",
       "4   pos  695994     NaN     NaN     NaN     NaN     NaN     0.0       0.0   \n",
       "\n",
       "      ag_002  ...     ee_002     ee_003     ee_004     ee_005     ee_006  \\\n",
       "0        0.0  ...   129862.0    26872.0    34044.0    22472.0    34362.0   \n",
       "1      222.0  ...  7908038.0  3026002.0  5025350.0  2025766.0  1160638.0   \n",
       "2   178226.0  ...  1432098.0   372252.0   527514.0   358274.0   332818.0   \n",
       "3  2186308.0  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "4        0.0  ...  1397742.0   495544.0   361646.0    28610.0     5130.0   \n",
       "\n",
       "     ee_007    ee_008  ee_009  ef_000  eg_000  \n",
       "0       0.0       0.0     0.0     0.0     0.0  \n",
       "1  533834.0  493800.0  6914.0     0.0     0.0  \n",
       "2  284178.0    3742.0     0.0     0.0     0.0  \n",
       "3       NaN       NaN     NaN     NaN     NaN  \n",
       "4     212.0       0.0     0.0     NaN     NaN  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 62,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis - EDA"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 63,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    35188\n",
       "pos     1000\n",
       "Name: class, dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 8,
=======
     "execution_count": 63,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of unique values of target column\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 64,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='class'>"
      ]
     },
<<<<<<< HEAD
     "execution_count": 9,
=======
     "execution_count": 64,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize class feature distribution\n",
    "sns.barplot(x =df['class'].value_counts().index , y = df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 65,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1 categorical features : ['class']\n",
      "\n",
      "We have 170 numerical features : ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n"
     ]
    }
   ],
   "source": [
    "# define numerical & categorical columns\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} categorical features : {}'.format(len(categorical_features), categorical_features))\n",
    "print('\\nWe have {} numerical features : {}'.format(len(numeric_features), numeric_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: As this is a sensor base data interpretation of each columns is not required. Instead we will check the distribution of the missing values in each column."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 66,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_missing</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br_000</th>\n",
       "      <td>29461</td>\n",
       "      <td>81.410965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bq_000</th>\n",
       "      <td>29132</td>\n",
       "      <td>80.501824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp_000</th>\n",
       "      <td>28514</td>\n",
       "      <td>78.794075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_000</th>\n",
       "      <td>27896</td>\n",
       "      <td>77.086327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cr_000</th>\n",
       "      <td>27896</td>\n",
       "      <td>77.086327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cj_000</th>\n",
       "      <td>203</td>\n",
       "      <td>0.560959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_000</th>\n",
       "      <td>203</td>\n",
       "      <td>0.560959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bt_000</th>\n",
       "      <td>86</td>\n",
       "      <td>0.237648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_000</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        number_of_missing  percent_missing\n",
       "br_000              29461        81.410965\n",
       "bq_000              29132        80.501824\n",
       "bp_000              28514        78.794075\n",
       "ab_000              27896        77.086327\n",
       "cr_000              27896        77.086327\n",
       "...                   ...              ...\n",
       "cj_000                203         0.560959\n",
       "ci_000                203         0.560959\n",
       "bt_000                 86         0.237648\n",
       "aa_000                  0         0.000000\n",
       "class                   0         0.000000\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 11,
=======
     "execution_count": 66,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'number_of_missing' : df.isnull().sum(),\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df = missing_value_df.sort_values('percent_missing',ascending=False)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 67,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize missing values\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.barplot(x = missing_value_df.index, y= missing_value_df['percent_missing'] )\n",
    "plt.xticks(fontsize=5, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 68,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['br_000', 'bq_000', 'bp_000', 'ab_000', 'cr_000', 'bo_000', 'bn_000']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 13,
=======
     "execution_count": 68,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns which has more than %70 of missing values\n",
    "drop_column_list  = list(missing_value_df[missing_value_df['percent_missing']>70].index)\n",
    "drop_column_list"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 69,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(drop_column_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 70,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36188, 164)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 15,
=======
     "execution_count": 70,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rows and columns after droping columns \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa_000</th>\n",
       "      <td>36188.0</td>\n",
       "      <td>6.591016e+04</td>\n",
       "      <td>1.641238e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>31026.0</td>\n",
       "      <td>50068.5</td>\n",
       "      <td>2.746564e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac_000</th>\n",
       "      <td>34047.0</td>\n",
       "      <td>3.535223e+08</td>\n",
       "      <td>7.926486e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>2.130707e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_000</th>\n",
       "      <td>26988.0</td>\n",
       "      <td>3.185447e+05</td>\n",
       "      <td>5.225398e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>8.584298e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ae_000</th>\n",
       "      <td>34601.0</td>\n",
       "      <td>7.234300e+00</td>\n",
       "      <td>1.864373e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.105000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>af_000</th>\n",
       "      <td>34601.0</td>\n",
       "      <td>1.160654e+01</td>\n",
       "      <td>2.344054e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.007000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee_007</th>\n",
       "      <td>35809.0</td>\n",
       "      <td>3.718051e+05</td>\n",
       "      <td>1.722483e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>42966.0</td>\n",
       "      <td>170608.0</td>\n",
       "      <td>3.727856e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee_008</th>\n",
       "      <td>35809.0</td>\n",
       "      <td>1.485117e+05</td>\n",
       "      <td>5.153265e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>143230.0</td>\n",
       "      <td>1.926740e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee_009</th>\n",
       "      <td>35809.0</td>\n",
       "      <td>8.897664e+03</td>\n",
       "      <td>5.316375e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3.810078e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef_000</th>\n",
       "      <td>34458.0</td>\n",
       "      <td>8.346393e-02</td>\n",
       "      <td>3.789020e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.620000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg_000</th>\n",
       "      <td>34459.0</td>\n",
       "      <td>2.092342e-01</td>\n",
       "      <td>8.613915e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.146000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          count          mean           std  min    25%      50%       75%  \\\n",
       "aa_000  36188.0  6.591016e+04  1.641238e+05  0.0  866.0  31026.0   50068.5   \n",
       "ac_000  34047.0  3.535223e+08  7.926486e+08  0.0   16.0    152.0     964.0   \n",
       "ad_000  26988.0  3.185447e+05  5.225398e+07  0.0   24.0    128.0     432.0   \n",
       "ae_000  34601.0  7.234300e+00  1.864373e+02  0.0    0.0      0.0       0.0   \n",
       "af_000  34601.0  1.160654e+01  2.344054e+02  0.0    0.0      0.0       0.0   \n",
       "...         ...           ...           ...  ...    ...      ...       ...   \n",
       "ee_007  35809.0  3.718051e+05  1.722483e+06  0.0  118.0  42966.0  170608.0   \n",
       "ee_008  35809.0  1.485117e+05  5.153265e+05  0.0    0.0   4278.0  143230.0   \n",
       "ee_009  35809.0  8.897664e+03  5.316375e+04  0.0    0.0      0.0    2018.0   \n",
       "ef_000  34458.0  8.346393e-02  3.789020e+00  0.0    0.0      0.0       0.0   \n",
       "eg_000  34459.0  2.092342e-01  8.613915e+00  0.0    0.0      0.0       0.0   \n",
       "\n",
       "                 max  \n",
       "aa_000  2.746564e+06  \n",
       "ac_000  2.130707e+09  \n",
       "ad_000  8.584298e+09  \n",
       "ae_000  2.105000e+04  \n",
       "af_000  2.007000e+04  \n",
       "...              ...  \n",
       "ee_007  3.727856e+07  \n",
       "ee_008  1.926740e+07  \n",
       "ee_009  3.810078e+06  \n",
       "ef_000  3.620000e+02  \n",
       "eg_000  1.146000e+03  \n",
       "\n",
       "[163 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
=======
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check distirbution of numeri features\n",
    "# numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "# \n",
    "# plt.figure(figsize=(15, 100))\n",
    "# for i, col in enumerate(numeric_features):\n",
    "#     plt.subplot(60, 3, i+1)\n",
    "#     sns.distplot(x=df[col], color='indianred')\n",
    "#     plt.xlabel(col, weight='bold')\n",
    "#     plt.tight_layout()"
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "* The target column 'class' is highly imbalanced which needs to be handled.\n",
    "\n",
    "* Interpreting each and every column is not necessary as this is sensor data.\n",
    "\n",
    "* Remaining missing values need to be handled as well.\n",
    "\n",
    "* Most of the features are not normally distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y\n",
    "X = df.drop('class', axis=1)\n",
<<<<<<< HEAD
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
=======
    "y = df['class']\n",
    "\n",
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
    "# encoding target variable\n",
    "y= y.replace({'pos': 1, 'neg': 0})"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 73,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary which contains models for experiment\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 : \n",
    "\n",
    "Scaling approach : Robust scaler  \n",
    "\n",
    "Null value approach : KNN Imputer\n",
    "\n",
    "Imbalanced handling approach : SMOTE+TOMEK \n",
    "\n",
<<<<<<< HEAD
    "Note : \n",
    "* Since most of the data is not normally distributed we can not use StandardScaler. \n",
    "\n",
    "* And most of the features has outliers so it is not good place to use min-max sacaler either. So we will use Robust Scaler. \n",
    "\n",
    "* Robust Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile)."
=======
    "NOTES : Most of the numeric columns are not normally distributed and has outluers so we can't use StandatdScaler and min-max. Instead we will use RobustScaler in this experiment. Robust scaler removes median and scales the data according the quartile.\n"
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 77,
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply robust scaler\n",
    "robust_scaler = RobustScaler()\n",
    "X_scaled = robust_scaler.fit_transform(X)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply KNN Imputer \n",
    "results = [] \n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "strategies  = [str(i) for i in [1,3,5,7,9]]\n",
    "for s in strategies :\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\n",
    "    score = mean(cross_val_score(pipeline, X_scaled, y , scoring='accuracy',cv=5,n_jobs=-1))\n",
    "    # results.append(scores)\n",
    "    print('n_neighbors= %s || accuracy (%.4f)' % (s , score))\n"
=======
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m n_weights_param:\n\u001b[0;32m      6\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39mn)),(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression())])\n\u001b[1;32m----> 7\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors= \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m || accuracy (\u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (n , mean(scores)))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#find best n value for KNN imputer\n",
    "results = [] \n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "n_weights_param = [1,3,5,7,9]\n",
    "for n in n_weights_param:\n",
    "    pipeline = Pipeline(steps=[('imputer', KNNImputer(n_neighbors=n)),('model', LogisticRegression())])\n",
    "    scores = cross_val_score(pipeline, X_scaled,y, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    print('n_neighbors= %s || accuracy (%.4f)' % (n , mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create knn(n=3) & robust scaler pipeline \n",
    "knn_pipeline = Pipeline(steps = [\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),\n",
    "    ('scaler', RobustScaler())\n",
    "])  \n",
    "\n",
    "X_knn_scaled = knn_pipeline.fit_transform(X)"
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "results=[]\n",
    "# define imputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "strategies = [str(i) for i in [1,3,5,7,9]]\n",
    "for s in strategies:\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\n",
    "    scores = cross_val_score(pipeline, X1, y, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    print('n_neighbors= %s || accuracy (%.4f)' % (s , mean(scores)))"
=======
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_knn_scaled, y)"
>>>>>>> 69cdad498bd38b9934f431682e4024bbba8ad007
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9929\n",
      "- F1 score: 0.9929\n",
      "- Precision: 0.9888\n",
      "- Recall: 0.9970\n",
      "- Roc Auc Score: 0.9929\n",
      "- COST: 11290.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9864\n",
      "- F1 score: 0.9865\n",
      "- Precision: 0.9807\n",
      "- Recall: 0.9923\n",
      "- Roc Auc Score: 0.9864\n",
      "- COST: 28370.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9839\n",
      "- F1 score: 0.9840\n",
      "- Precision: 0.9803\n",
      "- Recall: 0.9876\n",
      "- Roc Auc Score: 0.9839\n",
      "- COST: 179060.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9843\n",
      "- F1 score: 0.9844\n",
      "- Precision: 0.9811\n",
      "- Recall: 0.9876\n",
      "- Roc Auc Score: 0.9843\n",
      "- COST: 44830.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.5879\n",
      "- F1 score: 0.6930\n",
      "- Precision: 0.5523\n",
      "- Recall: 0.9300\n",
      "- Roc Auc Score: 0.5878\n",
      "- COST: 1194620.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.5810\n",
      "- F1 score: 0.6893\n",
      "- Precision: 0.5474\n",
      "- Recall: 0.9307\n",
      "- Roc Auc Score: 0.5813\n",
      "- COST: 296940.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9814\n",
      "- F1 score: 0.9816\n",
      "- Precision: 0.9707\n",
      "- Recall: 0.9927\n",
      "- Roc Auc Score: 0.9814\n",
      "- COST: 110900.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9744\n",
      "- F1 score: 0.9748\n",
      "- Precision: 0.9605\n",
      "- Recall: 0.9894\n",
      "- Roc Auc Score: 0.9744\n",
      "- COST: 39850.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9962\n",
      "- F1 score: 0.9962\n",
      "- Precision: 0.9935\n",
      "- Recall: 0.9989\n",
      "- Roc Auc Score: 0.9962\n",
      "- COST: 4460.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9994\n",
      "- F1 score: 0.9994\n",
      "- Precision: 0.9993\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9994\n",
      "- COST: 7690.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9950\n",
      "- F1 score: 0.9950\n",
      "- Precision: 0.9923\n",
      "- Recall: 0.9977\n",
      "- Roc Auc Score: 0.9950\n",
      "- COST: 8540.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9749\n",
      "- F1 score: 0.9750\n",
      "- Precision: 0.9736\n",
      "- Recall: 0.9763\n",
      "- Roc Auc Score: 0.9749\n",
      "- COST: 339420.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9756\n",
      "- F1 score: 0.9756\n",
      "- Precision: 0.9745\n",
      "- Recall: 0.9767\n",
      "- Roc Auc Score: 0.9756\n",
      "- COST: 83290.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get experiment 1 result\n",
    "report_experiment_1 = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>11290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>28370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>39850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>44830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>83290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>296940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name    Cost\n",
       "5           XGBClassifier    4460\n",
       "6  CatBoosting Classifier    8540\n",
       "0           Random Forest   11290\n",
       "1           Decision Tree   28370\n",
       "4  K-Neighbors Classifier   39850\n",
       "2       Gradient Boosting   44830\n",
       "7     AdaBoost Classifier   83290\n",
       "3     Logistic Regression  296940"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_experiment_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 : \n",
    "\n",
    "**Scaling approach :**  \n",
    "\n",
    "**Null value approach :** \n",
    "\n",
    "**Imbalanced handling approach :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 : \n",
    "\n",
    "**Scaling approach :**  \n",
    "\n",
    "**Null value approach :** \n",
    "\n",
    "**Imbalanced handling approach :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 : \n",
    "\n",
    "**Scaling approach :**  \n",
    "\n",
    "**Null value approach :** \n",
    "\n",
    "**Imbalanced handling approach :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5 : \n",
    "\n",
    "**Scaling approach :**  \n",
    "\n",
    "**Null value approach :** \n",
    "\n",
    "**Imbalanced handling approach :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
